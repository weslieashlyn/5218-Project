{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60328c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mxnet import autograd, gluon, init, npx\n",
    "from mxnet.gluon import nn\n",
    "from d2l import mxnet as d2l\n",
    "\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b0b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the Dataset\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['dog_tiny'] = (d2l.DATA_URL + 'kaggle_dog_tiny.zip', '0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d')\n",
    "\n",
    "demo = False\n",
    "if demo:\n",
    "    data_dir = d2l.download_extract('dog_tiny')\n",
    "else:\n",
    "    data_dir = os.path.join('Users', 'MadelineUdowa', 'dog-breed-identification')\n",
    "\n",
    "#change 'MadelineUdowa' to your systems name\n",
    "\n",
    "    #data_dir = \"C:/Users\"\n",
    "    #data_dir = os.path.realpath('/MadelineUdowa/dog-breed-identification')\n",
    "    #os.startfile(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa45b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organizing the Dataset\n",
    "\n",
    "def reorg_dog_data(data_dir, valid_ratio):\n",
    "    labels = d2l.read_csv_labels(os.path.join(data_dir, 'labels.csv'))\n",
    "    d2l.reorg_train_valid(data_dir, labels, valid_ratio)\n",
    "    d2l.reorg_test(data_dir)\n",
    "\n",
    "batch_size = 4 if demo else 128\n",
    "valid_ratio = 0.1\n",
    "reorg_dog_data(data_dir, valid_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03498aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Augmentation\n",
    "\n",
    "transform_train = gluon.data.vision.transforms.Compose([\n",
    "    # Randomly crop the image to obtain an image with an area of 0.08 to 1 of\n",
    "    # the original area and height to width ratio between 3/4 and 4/3. Then,\n",
    "    # scale the image to create a new image with a height and width of 224\n",
    "    # pixels each\n",
    "    gluon.data.vision.transforms.RandomResizedCrop(\n",
    "        224, scale=(0.08, 1.0), ratio=(3.0 / 4.0, 4.0 / 3.0)),\n",
    "    gluon.data.vision.transforms.RandomFlipLeftRight(),\n",
    "    # Randomly change the brightness, contrast, and saturation\n",
    "    gluon.data.vision.transforms.RandomColorJitter(brightness=0.4,\n",
    "                                                   contrast=0.4,\n",
    "                                                   saturation=0.4),\n",
    "    # Add random noise\n",
    "    gluon.data.vision.transforms.RandomLighting(0.1),\n",
    "    gluon.data.vision.transforms.ToTensor(),\n",
    "    # Standardize each channel of the image\n",
    "    gluon.data.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbef68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = gluon.data.vision.transforms.Compose([\n",
    "    gluon.data.vision.transforms.Resize(256),\n",
    "    # Crop a square of 224 by 224 from the center of the image\n",
    "    gluon.data.vision.transforms.CenterCrop(224),\n",
    "    gluon.data.vision.transforms.ToTensor(),\n",
    "    gluon.data.vision.transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e651735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Dataset\n",
    "\n",
    "train_ds, valid_ds, train_valid_ds, test_ds = [\n",
    "    gluon.data.vision.ImageFolderDataset(\n",
    "        os.path.join(data_dir, 'train_valid_test', folder))\n",
    "    for folder in ('train', 'valid', 'train_valid', 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, train_valid_iter = [\n",
    "    gluon.data.DataLoader(dataset.transform_first(transform_train),\n",
    "                          batch_size, shuffle=True, last_batch='discard')\n",
    "    for dataset in (train_ds, train_valid_ds)]\n",
    "\n",
    "valid_iter = gluon.data.DataLoader(valid_ds.transform_first(transform_test),\n",
    "                                   batch_size, shuffle=False,\n",
    "                                   last_batch='discard')\n",
    "\n",
    "test_iter = gluon.data.DataLoader(test_ds.transform_first(transform_test),\n",
    "                                  batch_size, shuffle=False,\n",
    "                                  last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862cce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Model\n",
    "\n",
    "def get_net(devices):\n",
    "    finetune_net = gluon.model_zoo.vision.resnet34_v2(pretrained=True)\n",
    "    # Define a new output network\n",
    "    finetune_net.output_new = nn.HybridSequential(prefix='')\n",
    "    finetune_net.output_new.add(nn.Dense(256, activation='relu'))\n",
    "    # There are 120 output categories\n",
    "    finetune_net.output_new.add(nn.Dense(120))\n",
    "    # Initialize the output network\n",
    "    finetune_net.output_new.initialize(init.Xavier(), ctx=devices)\n",
    "    # Distribute the model parameters to the CPUs or GPUs used for computation\n",
    "    finetune_net.collect_params().reset_ctx(devices)\n",
    "    return finetune_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357cfeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "def evaluate_loss(data_iter, net, devices):\n",
    "    l_sum, n = 0.0, 0\n",
    "    for features, labels in data_iter:\n",
    "        X_shards, y_shards = d2l.split_batch(features, labels, devices)\n",
    "        output_features = [net.features(X_shard) for X_shard in X_shards]\n",
    "        outputs = [net.output_new(feature) for feature in output_features]\n",
    "        ls = [\n",
    "            loss(output, y_shard).sum()\n",
    "            for output, y_shard in zip(outputs, y_shards)]\n",
    "        l_sum += sum([float(l.sum()) for l in ls])\n",
    "        n += labels.size\n",
    "    return l_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c569fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Training Functions\n",
    "\n",
    "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n",
    "          lr_decay):\n",
    "    # Only train the small custom output network\n",
    "    trainer = gluon.Trainer(net.output_new.collect_params(), 'sgd', {\n",
    "        'learning_rate': lr,\n",
    "        'momentum': 0.9,\n",
    "        'wd': wd})\n",
    "    num_batches, timer = len(train_iter), d2l.Timer()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'valid loss'])\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = d2l.Accumulator(2)\n",
    "        if epoch > 0 and epoch % lr_period == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            X_shards, y_shards = d2l.split_batch(features, labels, devices)\n",
    "            output_features = [net.features(X_shard) for X_shard in X_shards]\n",
    "            with autograd.record():\n",
    "                outputs = [\n",
    "                    net.output_new(feature) for feature in output_features]\n",
    "                ls = [\n",
    "                    loss(output, y_shard).sum()\n",
    "                    for output, y_shard in zip(outputs, y_shards)]\n",
    "            for l in ls:\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            metric.add(sum([float(l.sum()) for l in ls]), labels.shape[0])\n",
    "            timer.stop()\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (metric[0] / metric[1], None))\n",
    "        if valid_iter is not None:\n",
    "            valid_loss = evaluate_loss(valid_iter, net, devices)\n",
    "            animator.add(epoch + 1, (None, valid_loss))\n",
    "    if valid_iter is not None:\n",
    "        print(f'train loss {metric[0] / metric[1]:.3f}, '\n",
    "              f'valid loss {valid_loss:.3f}')\n",
    "    else:\n",
    "        print(f'train loss {metric[0] / metric[1]:.3f}')\n",
    "    print(f'{metric[1] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337cdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Validating the Model\n",
    "\n",
    "devices, num_epochs, lr, wd = d2l.try_all_gpus(), 5, 0.01, 1e-4\n",
    "lr_period, lr_decay, net = 10, 0.1, get_net(devices)\n",
    "net.hybridize()\n",
    "train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n",
    "      lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9432d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifying the Testing Set and SUbmitting Results on Kaggle\n",
    "\n",
    "net = get_net(devices)\n",
    "net.hybridize()\n",
    "train(net, train_valid_iter, None, num_epochs, lr, wd, devices, lr_period,\n",
    "      lr_decay)\n",
    "\n",
    "preds = []\n",
    "for data, label in test_iter:\n",
    "    output_features = net.features(data.as_in_ctx(devices[0]))\n",
    "    output = npx.softmax(net.output_new(output_features))\n",
    "    preds.extend(output.asnumpy())\n",
    "ids = sorted(\n",
    "    os.listdir(os.path.join(data_dir, 'train_valid_test', 'test', 'unknown')))\n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('id,' + ','.join(train_valid_ds.synsets) + '\\n')\n",
    "    for i, output in zip(ids, preds):\n",
    "        f.write(\n",
    "            i.split('.')[0] + ',' + ','.join([str(num)\n",
    "                                              for num in output]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab673fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08184b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
